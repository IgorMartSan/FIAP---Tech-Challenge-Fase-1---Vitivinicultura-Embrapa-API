

# âœ… EntregÃ¡veis do Projeto

- [x] API funcional com endpoints REST pÃºblicos e documentados.
- [x] AutenticaÃ§Ã£o via JWT. (Opicional)
- [x] DocumentaÃ§Ã£o dos endpoints via Swagger (`/docs`).
- [ ] Pipeline de ingestÃ£o e processamento funcionando.(Opicional)
- [x] DescriÃ§Ã£o clara da integraÃ§Ã£o com Machine Learning.
- [x] Diagrama da arquitetura adicionado no README.
- [ ] Link do deploy funcionando.



# âœ… EntregÃ¡veis do Projeto


username="admin"
password="automate123."



# ğŸ—ï¸ Plano de Deploy â€” API de Vitivinicultura + ML

## ğŸ”¥ DescriÃ§Ã£o do Projeto
Desenvolvimento de uma API com **FastAPI** que disponibiliza dados pÃºblicos de vitivinicultura da **Embrapa**.  
A API irÃ¡ alimentar uma pipeline de **Machine Learning**.

---

## ğŸš€ Arquitetura do Projeto

```plaintext
        +------------------------+
        |      UsuÃ¡rios/API      |
        +-----------+------------+
                    |
                    v
        +------------------------------+
        |      API - FastAPI (Nuvem)   |
        | - Consome dados da Embrapa   |
        | - Disponibiliza dados (JSON) |
        | - Endpoints documentados     |
        | - (Opcional) AutenticaÃ§Ã£o JWT|
        +---------------+--------------+
                        |
                        v
           +-------------------------------+
           |       Banco de Dados (Cloud)  |
           | - PostgreSQL / MongoDB        |
           | - Dados estruturados          |
           +---------------+---------------+
                           |
                           v
           +-------------------------------+
           | Pipeline de Machine Learning  |
           | - Coleta dados do DB          |
           | - Treinamento e inferÃªncia    |
           | - Salva previsÃµes no DB       |
           +-------------------------------+
```

## âš™ï¸ Componentes

### 1ï¸âƒ£ IngestÃ£o de Dados
- **Fonte:** Site da Embrapa (via requisicao HTTP).
- **Processo:**
  - Coleta via requisicao HTTPS dos dados das abas:
    - ProduÃ§Ã£o
    - Processamento
    - ComercializaÃ§Ã£o
    - ImportaÃ§Ã£o
    - ExportaÃ§Ã£o
  - TransformaÃ§Ã£o dos dados brutos em dados estruturados (Json).
- **Destino:** Pipeline de Machine Learning.

---

### 2ï¸âƒ£ API (FastAPI)
- **FunÃ§Ãµes principais:**
  - Consumir APIs pÃºblicas.
  - Fornecer endpoints REST para:
    - Consultar dados.
  - DocumentaÃ§Ã£o automÃ¡tica disponÃ­vel em `/docs`.
  - AutenticaÃ§Ã£o via JWT.
- **Tecnologias:**
  - Python + FastAPI.
  - Pydantic para validaÃ§Ã£o de dados.
  - SQLAlchemy (PostgreSQL).

---

### 3ï¸âƒ£ Banco de Dados
- **ResponsÃ¡vel por armazenar:**
  - Armazena usuÃ¡rio cadastrados para acesso a API.
- **Banco:**
  - PostgreSQL (relacional).
- **Hospedagem:**
  - AWS - Amazon RDS.

---

### 4ï¸âƒ£ Pipeline de Machine Learning
- **Pipeline Offline:**
  - ExtraÃ§Ã£o dos dados do banco.
  - Processamento, feature engineering e limpeza.
  - Treinamento de modelos preditivos (ex.: regressÃ£o, Ã¡rvore, redes neurais).
  - ValidaÃ§Ã£o e salvamento dos modelos.
- **Pipeline Online (Opcional):**
  - Deploy do modelo na prÃ³pria API como endpoint `/predict`.
  - Ou execuÃ§Ã£o periÃ³dica que gera previsÃµes e salva no banco.

---

## ğŸŒ Infraestrutura para Deploy

### ğŸš¢ ContainerizaÃ§Ã£o
- CriaÃ§Ã£o de **Dockerfile** para empacotar a API.
- **Docker Compose** para ambiente local, contendo:
  - API FastAPI.
  - Banco de dados (PostgreSQL ou MongoDB).

---

### â˜ï¸ Deploy em Nuvem
- **Plataformas recomendadas:**
  - Render.com
  - Railway.app
  - Fly.io
  - Heroku (para MVP)
- **ConfiguraÃ§Ãµes:**
  - VariÃ¡veis de ambiente sensÃ­veis:
    - `DB_URL`
    - `SECRET_KEY` (JWT)
    - `SITE_URL_EMBRAPA`
- **IntegraÃ§Ã£o com GitHub Actions (opcional):**
  - Deploy automÃ¡tico a cada push no `main`.

---

### ğŸ“Š Monitoramento e Logs
- Logs da API e containers:
  - Ferramentas sugeridas:
    - Logtail
    - Grafana Cloud + Loki
    - Axiom
- ImplementaÃ§Ã£o de healthchecks:
  - Endpoint `/health` para status da API.

---

## ğŸ”— Fluxo Completo do Sistema

```plaintext
[Embrapa] 
   â†“ (Scraping/API)
[API FastAPI]
   â†“ (POST dados)
[Banco de Dados]
   â†“ (Dataset limpo)
[Pipeline ML]
   â†“ (PrevisÃµes e anÃ¡lises)
[Banco de Dados]
   â†‘ (GET previsÃµes)
[API â†’ UsuÃ¡rio Final]

```

## ğŸ§  CenÃ¡rio de Machine Learning (Exemplo)

- **Problema:** PrevisÃ£o da produÃ§Ã£o de vinho nos prÃ³ximos anos.
- **Input:** Dados histÃ³ricos de:
  - ProduÃ§Ã£o
  - Clima
  - ComercializaÃ§Ã£o
  - ImportaÃ§Ã£o
  - ExportaÃ§Ã£o
- **Output:**
  - PrevisÃµes de produÃ§Ã£o futura.
  - AnÃ¡lise de tendÃªncias de mercado.
- **Entrega:**
  - Endpoint na API `/predict` com dados de entrada dinÃ¢micos.
  - Ou execuÃ§Ã£o periÃ³dica que salva previsÃµes no banco para consultas futuras.

---

## ğŸ“¦ Estrutura do RepositÃ³rio (Exemplo)

```plaintext
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Arquivo principal da API
â”‚   â”œâ”€â”€ api/                   # Rotas e endpoints
â”‚   â”œâ”€â”€ models/                # Models do banco
â”‚   â”œâ”€â”€ services/              # LÃ³gica de scraping e ingestÃ£o
â”‚   â”œâ”€â”€ utils/                 # FunÃ§Ãµes auxiliares
â”‚   â””â”€â”€ schemas/               # Schemas Pydantic
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ pipeline.py            # Pipeline de dados para ML
â”‚   â”œâ”€â”€ model.pkl              # Modelo treinado
â”‚   â””â”€â”€ predict.py             # Script de prediÃ§Ã£o
â”œâ”€â”€ Dockerfile                 # Dockerfile da API
â”œâ”€â”€ docker-compose.yml         # Compose para API + DB
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
```


